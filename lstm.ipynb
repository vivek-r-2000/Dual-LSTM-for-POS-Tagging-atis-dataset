{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqTnZAbEZ8iF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "import conllu\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# device = 'cpu'\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3ffjalhskNQd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "La5Rd4RsZ8iH"
      },
      "outputs": [],
      "source": [
        "# Read data from the conllu files\n",
        "trainingData = open(\"UD_English-Atis/en_atis-ud-train.conllu\", \"r\", encoding=\"utf-8\").read()\n",
        "testingData = open(\"UD_English-Atis/en_atis-ud-test.conllu\", \"r\", encoding=\"utf-8\").read()\n",
        "\n",
        "trainSentences = conllu.parse(trainingData)\n",
        "testSentences = conllu.parse(testingData)\n",
        "\n",
        "taggedTrainSentences = []\n",
        "\n",
        "for sentence in trainSentences:\n",
        "    taggedSentence = []\n",
        "    for i in range(len(sentence)):\n",
        "        taggedSentence.append((sentence[i]['form'], sentence[i]['upos']))\n",
        "    taggedTrainSentences.append(taggedSentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aQj2DbElZ8iI"
      },
      "outputs": [],
      "source": [
        "def word2index(word, ix):\n",
        "    return torch.tensor(ix[word], dtype=torch.long)\n",
        "\n",
        "def char2index(char, ix):\n",
        "    return torch.tensor(ix[char], dtype=torch.long)\n",
        "\n",
        "def tag2index(tag, ix):\n",
        "    return torch.tensor(ix[tag], dtype=torch.long)\n",
        "\n",
        "def sequence2index(sequence, ix):\n",
        "    return torch.tensor([ix[s] for s in sequence], dtype=torch.long)\n",
        "\n",
        "word2index = {}\n",
        "tag2index = {}\n",
        "char2index = {}\n",
        "for sentence in taggedTrainSentences:\n",
        "    for word, pos_tag in sentence:\n",
        "        if word not in word2index.keys():\n",
        "            word2index[word] = len(word2index)\n",
        "        if pos_tag not in tag2index.keys():\n",
        "            tag2index[pos_tag] = len(tag2index)\n",
        "        for char in word:\n",
        "            if char not in char2index.keys():\n",
        "                char2index[char] = len(char2index)\n",
        "\n",
        "word_vocab_size = len(word2index)\n",
        "tag_vocab_size = len(tag2index)\n",
        "char_vocab_size = len(char2index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_EMBEDDING_DIM = 1024\n",
        "CHAR_EMBEDDING_DIM = 128\n",
        "WORD_HIDDEN_DIM = 1024\n",
        "CHAR_HIDDEN_DIM = 1024\n",
        "EPOCHS = 10\n",
        "\n",
        "class DualLSTMTagger(nn.Module):\n",
        "    def __init__(self, wordEmbeddingDimension, wordHiddenDimension, charEmbeddingDimension, charHiddenDimension,\n",
        "                 wordVocabSize, charVocabSize, tagVocabSize):\n",
        "        super(DualLSTMTagger, self).__init__()\n",
        "        self.wordEmbedding = nn.Embedding(wordVocabSize, wordEmbeddingDimension)\n",
        "\n",
        "        self.charEmbedding = nn.Embedding(charVocabSize, charEmbeddingDimension)\n",
        "        self.charLSTM = nn.LSTM(charEmbeddingDimension, charHiddenDimension)\n",
        "\n",
        "        self.lstm = nn.LSTM(wordEmbeddingDimension + charHiddenDimension, wordHiddenDimension)\n",
        "        self.hidden2tag = nn.Linear(wordHiddenDimension, tagVocabSize)\n",
        "\n",
        "    def forward(self, sentence, words):\n",
        "        embeds = self.wordEmbedding(sentence)\n",
        "        charHiddenTotal = []\n",
        "        for word in words:\n",
        "            charEmbedded = self.charEmbedding(word)\n",
        "            _, (charHidden, char_cell_state) = self.charLSTM(charEmbedded.view(len(word), 1, -1))\n",
        "            word_char_hidden_state = charHidden.view(-1)\n",
        "            charHiddenTotal.append(word_char_hidden_state)\n",
        "        charHiddenTotal = torch.stack(tuple(charHiddenTotal))\n",
        "\n",
        "        combined = torch.cat((embeds, charHiddenTotal), 1)\n",
        "\n",
        "        output, _ = self.lstm(combined.view(len(sentence), 1, -1))\n",
        "        tagSpace = self.hidden2tag(output.view(len(sentence), -1))\n",
        "\n",
        "        tagScores = F.log_softmax(tagSpace, dim=1)\n",
        "        return tagScores\n",
        "\n",
        "model = DualLSTMTagger(WORD_EMBEDDING_DIM, WORD_HIDDEN_DIM, CHAR_EMBEDDING_DIM, CHAR_HIDDEN_DIM, word_vocab_size,\n",
        "                      char_vocab_size, tag_vocab_size)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "H8xQCxJ4ciVx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossList = []\n",
        "\n",
        "interval = round(len(taggedTrainSentences) / 100.)\n",
        "epochInterval = round(EPOCHS / 2.)\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    epochLoss = 0\n",
        "\n",
        "    for taggedSentence in taggedTrainSentences:\n",
        "        words = []\n",
        "        sentence = []\n",
        "        targets = []\n",
        "\n",
        "        for word in taggedSentence:\n",
        "            words.append(torch.tensor(sequence2index(word[0], char2index), dtype=torch.long).to(device))\n",
        "            sentence.append(word[0])\n",
        "            targets.append(word[1])\n",
        "\n",
        "        sentence = torch.tensor(sequence2index(sentence, word2index), dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(sequence2index(targets, tag2index), dtype=torch.long).to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        tagScores = model(sentence, words)\n",
        "\n",
        "        loss = criterion(tagScores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epochLoss += loss.item()\n",
        "        _, indices = torch.max(tagScores, 1)\n",
        "\n",
        "    epochLoss = epochLoss / len(taggedTrainSentences)\n",
        "    lossList.append(float(epochLoss))\n",
        "\n",
        "    if (epoch + 1) % epochInterval == 0:\n",
        "        print(f\"Epoch {epoch+1} Completed,\\tLoss {np.mean(lossList[-epochInterval:])}\")\n"
      ],
      "metadata": {
        "id": "wQgsrDCbdMFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7811d8d-506f-450f-ccad-c6c3de88eca7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 5/10 [09:19<09:18, 111.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Completed,\tLoss 0.2811941445917349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [18:37<00:00, 111.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Completed,\tLoss 0.28733548180116397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testSentence = input(\"Please enter sentence:\")\n",
        "testSequence = testSentence.split()\n",
        "\n",
        "with torch.no_grad():\n",
        "    words = [torch.tensor(sequence2index(s[0], char2index), dtype=torch.long).to(device) for s in testSequence]\n",
        "    sentence = torch.tensor(sequence2index(testSequence, word2index), dtype=torch.long).to(device)\n",
        "\n",
        "    tagScores = model(sentence, words)\n",
        "    _, indices = torch.max(tagScores, 1)\n",
        "    ans = []\n",
        "    for i in range(len(indices)):\n",
        "        for key, value in tag2index.items():\n",
        "            if indices[i] == value:\n",
        "                ans.append((testSequence[i], key))\n",
        "    print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF7MtrSXpSXF",
        "outputId": "01817dee-370e-44a7-dc35-6e803d40f5ea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter sentence:airplanes can fly\n",
            "[('airplanes', 'NOUN'), ('can', 'AUX'), ('fly', 'VERB')]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}